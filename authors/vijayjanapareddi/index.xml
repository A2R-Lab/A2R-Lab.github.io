<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>A²R Lab</title>
    <link>https://a2r-lab.github.io/authors/vijayjanapareddi/</link>
    <description>Recent content on A²R Lab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; {year} Brian Plancher</copyright>
    <lastBuildDate>Thu, 15 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://a2r-lab.github.io/authors/vijayjanapareddi/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Datasheets for Machine Learning Sensors</title>
      <link>https://a2r-lab.github.io/publication/mlsensorsdatasheet/</link>
      <pubDate>Thu, 15 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/mlsensorsdatasheet/</guid>
      <description>This paper introduces a standard datasheet template for ML sensors and discusses its essential components inluding: the system&amp;rsquo;s hardware, ML model and dataset attributes, end-to-end performance metrics, and environmental impact. We provide an example datasheet for our own ML sensor and discuss each section in detail. We highlight how these datasheets can facilitate better understanding and utilization of sensor data in ML applications, and we provide objective measures upon which system performance can be evaluated and compared.</description>
    </item>
    
    <item>
      <title>Machine Learning Sensors: A Design Paradigm for the Future of Intelligent Sensors</title>
      <link>https://a2r-lab.github.io/publication/mlsensorscacm/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/mlsensorscacm/</guid>
      <description>In this viewpoint we propose the ML sensor: a logical framework for developing ML-enabled embedded systems which empowers end users through its privacy-by-design approach. By limiting the data interface, the ML sensor paradigm helps ensure that no user information can be extracted beyond the scope of the sensor’s functionality. Our proposed definition is as follows: An ML sensor is a self-contained, embedded system that utilizes machine learning to process sensor data on-device – logically decoupling data computation from the main application processor and limiting the data access of the wider system to high-level ML model outputs.</description>
    </item>
    
    <item>
      <title>Is TinyML Sustainable? Assessing the Environmental Impacts of Machine Learning on Microcontrollers</title>
      <link>https://a2r-lab.github.io/publication/sustainabletinyml/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/sustainabletinyml/</guid>
      <description>The sustained growth of carbon emissions and global waste elicits significant sustainability concerns for our environment&amp;rsquo;s future. The growing Internet of Things (IoT) has the potential to exacerbate this issue. However, an emerging area known as Tiny Machine Learning (TinyML) has the opportunity to help address these environmental challenges through sustainable computing practices. TinyML, the deployment of machine learning (ML) algorithms onto low-cost, low-power microcontroller systems, enables on-device sensor analytics that unlocks numerous always-on ML applications. This article discusses the potential of these TinyML applications to address critical sustainability challenges. Moreover, the footprint of this emerging technology is assessed through a complete life cycle analysis of TinyML systems. From this analysis, TinyML presents opportunities to offset its carbon emissions by enabling applications that reduce the emissions of other sectors. Nevertheless, when globally scaled, the carbon footprint of TinyML systems is not negligible, necessitating that designers factor in environmental impact when formulating new devices. Finally, research directions for enabling further opportunities for TinyML to contribute to a sustainable future are outlined.</description>
    </item>
    
    <item>
      <title>RobotCore: An Open Architecture for Hardware Acceleration in ROS 2</title>
      <link>https://a2r-lab.github.io/publication/robotcore/</link>
      <pubDate>Thu, 30 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/robotcore/</guid>
      <description>We introduce RobotCore, an architecture to integrate hardware acceleration in the widely-used ROS 2 robotics software framework. This architecture is target-agnostic (supports edge, workstation, data center, or cloud targets) and accelerator-agnostic (supports both FPGAs and GPUs). It builds on top of the common ROS 2 build system and tools and is easily portable across different research and commercial solutions through a new firmware layer. We also leverage the Linux Tracing Toolkit next generation (LTTng) for low-overhead real-time tracing and benchmarking. To demonstrate the acceleration enabled by this architecture, we design an intra-FPGA ROS 2 node communication queue to enable faster data flows, and use it in conjunction with FPGA-accelerated nodes to achieve a 24.42% speedup over a CPU.</description>
    </item>
    
    <item>
      <title>Closing the Sim-to-Real Gap for Ultra-Low-Cost, Resource-Constrained, Quadruped Robot Platforms</title>
      <link>https://a2r-lab.github.io/publication/bittlesim2real/</link>
      <pubDate>Mon, 27 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/bittlesim2real/</guid>
      <description>As a step toward robust learning pipelines for these constrained robot platforms, we demonstrate how existing state-of-the-art imitation learning pipelines can be modified and augmented to support low-cost, limited hardware. By reducing our model’s observational space, leveraging TinyML to quantize our model, and adjusting the model outputs through post-processing, we are able to learn and deploy successful walking gaits on an 8-DoF, $299 (USD) toy quadruped robot that has reduced actuation and sensor feedback, as well as limited computing resources.</description>
    </item>
    
    <item>
      <title>Tiny Robot Learning: Challenges and Directions for Machine Learning in Resource-Constrained Robots</title>
      <link>https://a2r-lab.github.io/publication/tinyrobotlearning/</link>
      <pubDate>Wed, 15 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/tinyrobotlearning/</guid>
      <description>Tiny robot learning lies at the intersection of embedded systems, robotics, and ML, compounding the challenges of these domains. This paper gives a brief survey of the tiny robot learning space, elaborates on key challenges, and proposes promising opportunities for future work in ML system design.</description>
    </item>
    
    <item>
      <title>TinyML: Applied AI for Development</title>
      <link>https://a2r-lab.github.io/publication/tinymlunsti22/</link>
      <pubDate>Thu, 05 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/tinymlunsti22/</guid>
      <description>We believe that TinyML has a significant role to play in achieving the SDGs and facilitating scientific research in areas such as environmental monitoring, physics of complex systems and energy management. To broaden access and participation and increase the impact of this new technology, we present an initiative that is creating and supporting a global network of academic institutions working on TinyML in developing countries. We suggest the development of additional open educational resources, South–South academic collaboration and pilot projects of at-scale TinyML solutions aimed at addressing the SDGs.</description>
    </item>
    
    <item>
      <title>TinyMLedu: The Tiny Machine Learning Open Education Initiative</title>
      <link>https://a2r-lab.github.io/publication/tinymledu/</link>
      <pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/tinymledu/</guid>
      <description>&lt;a href=&#34;https://tinymledu.org&#34;&gt;TinyMLedu&lt;/a&gt; is working to build an international coalition of researchers and practitioners advancing TinyML in the developing world, and to develop and share high-quality, open-access educational materials globally.</description>
    </item>
    
    <item>
      <title>GRiD: GPU-Accelerated Rigid Body Dynamics with Analytical Gradients</title>
      <link>https://a2r-lab.github.io/publication/grid/</link>
      <pubDate>Thu, 24 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/grid/</guid>
      <description>We introduce and release GRiD, an open-source, GPU-accelerated library for computing rigid body dynamics with analytical gradients. GRiD was designed to accelerate nonlinear trajectory optimization through optimized code generation, GRiD provides as much as a 7.2x speedup over a state-of-the-art, multi-threaded CPU implementation and maintains as much as a 2.5x speedup when accounting for I/O overhead.</description>
    </item>
    
    <item>
      <title>Widening Access to Applied Machine Learning with TinyML</title>
      <link>https://a2r-lab.github.io/publication/wideningaccesswithtinyml/</link>
      <pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/wideningaccesswithtinyml/</guid>
      <description>In this paper, we describe our pedagogical approach to increasing access to applied ML through a four part massive open online course (MOOC) on Tiny Machine Learning (TinyML) produced in collaboration between academia (Harvard University) and industry (Google). We suggest that TinyML, ML on resource-constrained embedded devices, is an attractive means to widen access because TinyML both leverages low-cost and globally accessible hardware, and encourages the development of complete, self-contained applications, from data collection to deployment. We also released the course materials publicly, hoping they will inspire the next generation of ML practitioners and educators and further broaden access to cutting-edge ML technologies.</description>
    </item>
    
    <item>
      <title>Robomorphic Computing: A Design Methodology for Domain-Specific Accelerators Parameterized by Robot Morphology</title>
      <link>https://a2r-lab.github.io/publication/robomorphic/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/robomorphic/</guid>
      <description>We introduce robomorphic computing; a methodology to transform robot morphology into a customized hardware accelerator morphology. In this work, we (i) present this design methodology; (ii) use the methodology to generate a parameterized accelerator design for the gradient of rigid body dynamics; (iii) evaluate FPGA and synthesized ASIC implementations; and (iv) describe how the design can be automatically customized for other robot models. Our FPGA accelerator achieves speedups of 8x and 86x over CPU and GPU latency, and maintains an overall speedup of 1.9x to 2.9x deployed in an end-to-end coprocessor system. ASIC synthesis indicates an additional factor of 7.2x.</description>
    </item>
    
    <item>
      <title>Accelerating Robot Dynamics Gradients on a CPU, GPU, and FPGA</title>
      <link>https://a2r-lab.github.io/publication/accellrbdgrad/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://a2r-lab.github.io/publication/accellrbdgrad/</guid>
      <description>In this paper, we detail the designs of three faster than state-of-the-art implementations of the gradient of rigid body dynamics on a CPU, GPU, and FPGA. Our optimized FPGA and GPU implementations provide as much as a 3.0x end-to-end speedup over our optimized CPU implementation by refactoring the algorithm to exploit its computational features, e.g., parallelism at different granularities.</description>
    </item>
    
  </channel>
</rss>
